{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belouspavel/yolov8/blob/main/YOLOv8_ipynb_%D1%81%D0%B2%D0%BE%D0%B4_10_0%2B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iBxWaQId_uW"
      },
      "source": [
        "# Основная часть\n",
        "\n",
        "Реализовано раздельное детектирование и треккинг объектов по уже готовым массивам из детекции, что позволяет подбирать архитектуру трекера и постобработки изолировано, без необходимости запуска предикта YOLO (ускорение подбора треккера и постобработки примерно в 100 раз и без траты лимита GPU в колаб) - также потенциально возможна генетика архитектуры постобработки и треккинга. Кроме того, реализован проброс касок и жилетов мимо трекера, что позволяет лучше трековать людей, а также не приводит к фильтрации касок и жилетов трекером, это позволяет лучше детектировать нарушения, избегать ложных фиксаций нарушений. Также реализовано восстановление в массиве информации нетрекованных боксов людей (которые трекер отфильтровал, отбросил).\n",
        "В постобработке реализовано два подхода по подсчету людей а также вероятностный подход фиксации нарушений. Под вероятностным понимается отношение количества кадров в которых конкретный айди находится в каске и жилете к общему количеству кадров с этим айди (отношение больше минимального порога - нарушения нет).\n",
        "\n",
        "У нас рабочий ноутбук, есть закомментированные строки кода. Закомментированные строки кода можно удалить (это вариации кода которые отключены - без них код работает), за исключением сохранения детекции по модели - эта часть кода закомментирована потому что понадобится один, первый раз для сохранения детекций сделанной рассматриваемой вариацией модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF38gPBa_TgF"
      },
      "source": [
        "## Загрузка датасэта"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JilFHfxd9ci",
        "outputId": "cf5cfd75-e6a3-49df-9946-be53411d0405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive           # у кого автоматически не подключается гугл диск\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxEPLFb_Mt4P",
        "outputId": "a0159681-e635-426c-f5f4-9feaa13419df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.77-py3-none-any.whl (513 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.22.4)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.15.1+cu118)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.10.1)\n",
            "Collecting sentry-sdk\n",
            "  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from ultralytics) (5.9.4)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (8.4.0)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.0.0+cu118)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->ultralytics) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: sentry-sdk, thop, ultralytics\n",
            "Successfully installed sentry-sdk-1.19.1 thop-0.1.1.post2209072238 ultralytics-8.0.77\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from filterpy) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from filterpy) (1.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from filterpy) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (1.4.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->filterpy) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.16.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110473 sha256=0be9b713a7464fee7d8b814515bf97c18c2d243eb03b12fc5cbd9a308788d137\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/e6/de/a09ea01e923aaf88b9f8c7c44329e857b2c1a31901167e55e6\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.9/dist-packages (0.4.8)\n",
            "Cloning into 'OC_SORT'...\n",
            "remote: Enumerating objects: 493, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 493 (delta 44), reused 74 (delta 42), pack-reused 409\u001b[K\n",
            "Receiving objects: 100% (493/493), 43.28 MiB | 20.12 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install filterpy\n",
        "!pip install imageio-ffmpeg\n",
        "!git clone https://github.com/noahcao/OC_SORT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdtcV2ZKNwpK"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "%cd OC_SORT\n",
        "from trackers.ocsort_tracker.ocsort import OCSort\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from ultralytics.yolo.utils.checks import check_requirements\n",
        "import matplotlib.pyplot as plt\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import cv2 \n",
        "import os\n",
        "from google.colab import files\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "%matplotlib inline\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhQFiyYfdMGq"
      },
      "outputs": [],
      "source": [
        "def get_boxes(result):\n",
        "  orig_shp = result[0].orig_shape\n",
        "  all_boxes = np.empty((0, 7))\n",
        "  for i in range(len(result)):\n",
        "    bbox = result[i].cpu().boxes.data.numpy()\n",
        "    bbox = np.hstack((bbox, np.tile(i, (bbox.shape[0], 1))))\n",
        "    all_boxes = np.vstack((all_boxes, bbox))\n",
        "  return result, all_boxes, orig_shp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrWoKy00oCWj"
      },
      "source": [
        "## Обучение и сохранение детекции по набору видео\n",
        "Эту часть кода можно (нужно) выполнить только один раз для одной модели. Потом можно закоментить, мы будем использовать готовые файлы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb0dN4Cc2wCL",
        "outputId": "14bbd110-7bf2-4fd1-cc08-54a1f96d3afc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to yolov8s.pt...\n",
            "100%|██████████| 21.5M/21.5M [00:01<00:00, 21.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "## дообучение \n",
        "# model = YOLO('yolov8s.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rL5Je7Q1aJY8"
      },
      "outputs": [],
      "source": [
        "# model.train(data='/content/drive/MyDrive/dataset-v1.2/data_custom.yaml', epochs=20)  # Обучаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QuV4ynCXF23b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/runs/detect/train/weights/best.pt') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bd9Vaa0zgbVY"
      },
      "outputs": [],
      "source": [
        "# path = '/content/drive/MyDrive/best.pt/45/'   ## Модель    \n",
        "# _best_pt = 'best45.pt'\n",
        "# for N in range(1,44): # устанавливаем какое видео смотрим\n",
        "#     try:\n",
        "#         with open(f'/content/drive/MyDrive/dataset-v1.1/test/{N}.mp4', 'r') as f:\n",
        "#           model = YOLO(path+_best_pt)  ## каждый раз инициализируем модель в колабе иначе выдает ошибочный результат\n",
        "#           results, all_boxes, orig_shape = get_boxes(model.predict(f'/content/drive/MyDrive/dataset-v1.1/test/{N}.mp4',\n",
        "#                                                                 line_thickness = 2,vid_stride = 1, save = True))\n",
        "#           # np.save(path + f\"{N}.npy\", np.array((orig_shape, all_boxes)))\n",
        "#           # df_all_boxes = pd.DataFrame(all_boxes)\n",
        "#           # df_all_boxes.to_excel(path + f\"df_{N}_{orig_shape[1]}_.xlsx\")\n",
        "\n",
        "#     except:    \n",
        "#         print(f'Видео {N}: отсутствует')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE97uS-moLPa"
      },
      "source": [
        "## Трекккинг и постобработка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvkHNju3WGBw"
      },
      "source": [
        "### Функции для подготовки фреймов данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPVdjumdD4Pi"
      },
      "outputs": [],
      "source": [
        "def change_bbox(bbox, tail):\n",
        "    y2 = bbox[:, [1]] + tail\n",
        "\n",
        "    bbox[:, [3]] = y2\n",
        "\n",
        "    return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZAZWOVGAvQt"
      },
      "outputs": [],
      "source": [
        "def forward(bbox,tracks): # эта функция позволяет сохранить лист детекций в который внесены айди от трека сохраняя нетрекованные боксы на случай последующей перетрековки\n",
        "  person = np.empty((0, 8))           # Создадим пустой массив для каждого кадра который будем наполнять\n",
        "  for i, bb in enumerate(bbox):  #Сравним каждый первичный не треккованный бокс\n",
        "    for k, t in enumerate(tracks):  # С каждым треккованым\n",
        "      if round(t[0]) == round(bb[0]) and round(t[1]) == round(bb[1]) and round(t[2]) == round(bb[2]) and round(t[3]) == round(bb[3]):   # Если у них совпадают координаты\n",
        "        bb_tr = np.copy(bb)\n",
        "        bb_tr = np.insert(bb_tr, 6, t[4])     # Добавляем к нетрекованному боксу трек определенный треккером (таким образом сохраняя конфиденс и класс)\n",
        "        person = np.vstack((person,bb_tr))        # Складываем массив. На этом этапе остались в стеке только трекованные боксы. Но нам хотелось бы сохранить их все для фиксации нарушений или последующей перетрековки\n",
        "      else:\n",
        "        pass\n",
        "    # if sum(np.in1d(bb[:4],tracks[:,:4])) < 4: # добавим в оттрекованный массив то что треккер отсеял (на случай перетрековки)\n",
        "    #   person = np.vstack((person,np.insert(bb, 6, -1)))\n",
        "  \n",
        "  return person"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ3gVwV0pOsx"
      },
      "outputs": [],
      "source": [
        "# def tracking_on_detect(all_boxes,tracker,orig_shp, tail):\n",
        "def tracking_on_detect(all_boxes,tracker,orig_shp):\n",
        "  all_boxes_tr = np.empty((0, 8))\n",
        "  for i in range(int(max(all_boxes[:, -1]))):\n",
        "    bbox = all_boxes[all_boxes[:, -1] == i]\n",
        "    bbox_unif = bbox[np.where(bbox[:,5] != 0)][:,:6]  # отбираем форму и каски в отдельный массив который прокинем мимо трека\n",
        "    bbox_unif = np.hstack((bbox_unif, np.tile(np.nan, (bbox_unif.shape[0], 1)))) # добавляем столбец с айди нан для касок и жилетов\n",
        "    bbox_unif = np.hstack((bbox_unif, np.tile(i, (bbox_unif.shape[0], 1)))) # сохраняем номер кадра\n",
        "    bbox = bbox[np.where(bbox[:,5] == 0)] #в трек идут только люди\n",
        "    # bbox = change_bbox(bbox, tail)\n",
        "    tracks = tracker.update(bbox[:, :-2], img_size = orig_shp, img_info = orig_shp) # трекуем людей\n",
        "    person = forward(bbox,tracks) # эта функция позволяет использовать далее лист детекций в который внесены айди от трека (трек фильтрует и удаляет боксы) \n",
        "    all_boxes_tr = np.vstack((all_boxes_tr, person)) # складываем людей в массив\n",
        "    all_boxes_tr = np.vstack((all_boxes_tr, bbox_unif)) # складываем каски и жилеты в массив\n",
        "  return all_boxes_tr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_video_with_bbox(bboxes, video_source, video_out): # функция отрисовки боксов на соответсвующем видео\n",
        "  '''Функция записывает видео с рамками объектов, которые передаются в:\n",
        "  bboxes - ndarray(x1, y1, x2, y2, conf, class, id, frame),\n",
        "  если последовательность нарушена надо менять внутри функции.\n",
        "  Другие обязательные аргументы функции:\n",
        "  video_source - полный путь до исходного видео, на которое нужно наложить рамки;\n",
        "  video_out - полный путь вновь создаваемого видео. Путь должен быть,\n",
        "  а файла - не должно быть'''\n",
        "  vid_src = cv2.VideoCapture(video_source)\n",
        "  if vid_src.isOpened():\n",
        "    # Разрешение кадра\n",
        "    frame_size = (int(vid_src.get(3)), int(vid_src.get(4)))\n",
        "    # Количество кадров в секунду\n",
        "    fps = int(vid_src.get(5))\n",
        "    # Количество кадров в файле\n",
        "    len_frm = int(vid_src.get(7))\n",
        "    # Выходное изображение записываем\n",
        "    vid_out = cv2.VideoWriter(video_out, cv2.VideoWriter_fourcc(* 'XVID'),\n",
        "                              fps, frame_size)\n",
        "    # Пройдемся по всем кадрам\n",
        "    for i in range(len_frm):\n",
        "      ret, frame = vid_src.read()\n",
        "      # На всякий пожарный случай выход\n",
        "      if not ret: break\n",
        "      # Отбираем рамки для кадра\n",
        "      bbox = bboxes[bboxes[:, -1] == i, :-1]\n",
        "      if len(bbox) > 0:\n",
        "        # Только люди\n",
        "        pbox = bbox[bbox[:, 5] == 0]\n",
        "        for p in pbox:\n",
        "          # Добавим рамки\n",
        "          x1, y1 = int(p[0]), int(p[1])\n",
        "          x2, y2 = int(p[2]), int(p[3])\n",
        "          cv2.rectangle(frame, (x1, y1), (x2, y2), (153,153,153), 2)\n",
        "          # Добавим надпись в виде идентификатора объекта  и conf\n",
        "          msg = 'id' + str(int(p[6])) + ' ' + str(round(p[4], 2))\n",
        "          (w, h), _ = cv2.getTextSize(msg, cv2.FONT_HERSHEY_DUPLEX, 0.45, 1)\n",
        "          cv2.rectangle(frame, (x1, y1 - 20), (x1 + w, y1), (153,153,153), -1)\n",
        "          cv2.putText(frame, msg, (x1, y1 - 5), cv2.FONT_HERSHEY_DUPLEX, 0.45,\n",
        "                      (255,255,255), 1)\n",
        "        # Отрисовываем рамки касок\n",
        "        helmets = bbox[bbox[:, 5] == 1]\n",
        "        for helmet in helmets:\n",
        "          x1, y1 = int(helmet[0]), int(helmet[1])\n",
        "          x2, y2 = int(helmet[2]), int(helmet[3])\n",
        "          cv2.rectangle(frame, (x1, y1), (x2, y2), (51,255,204), 2)\n",
        "        # Отрисовываем рамки жилетов\n",
        "        vests = bbox[bbox[:, 5] == 2]\n",
        "        for vest in vests:\n",
        "          x1, y1 = int(vest[0]), int(vest[1])\n",
        "          x2, y2 = int(vest[2]), int(vest[3])\n",
        "          cv2.rectangle(frame, (x1, y1), (x2, y2), (51,204,255), 2)\n",
        "      # Записываем кадр\n",
        "      vid_out.write(frame)\n",
        "    # Освобождаем видео\n",
        "    vid_out.release()\n",
        "    vid_src.release()\n",
        "  else: print('Видеофайл недоступен')\n",
        "  # Заклинание cv2\n",
        "  cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "NZEbYL-irn_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilh7qWXyThNP"
      },
      "outputs": [],
      "source": [
        "def get_men(out_boxes):\n",
        "  men = np.empty((0, 9))\n",
        "  inter_helm = 60 # поле вокруг бб человека для детекции касок \n",
        "  inter_unif = 15 # поле вокруг бб человека для детекции жилетов\n",
        "  for i in range(int(max(out_boxes[:, -1]))):\n",
        "   \n",
        "    # Только люди\n",
        "    humans = out_boxes[(out_boxes[:, -3] == 0) & (out_boxes[:, -2] != -1) & (out_boxes[:, -1] == i)]\n",
        "    # Только каски\n",
        "    helmets = out_boxes[(out_boxes[:, -3] == 1) & (out_boxes[:, -1] == i)]\n",
        "    # Только жилетки\n",
        "    vests = out_boxes[(out_boxes[:, -3] == 2) & (out_boxes[:, -1] == i)]\n",
        "\n",
        "    # Персональный подход к каждому человеку\n",
        "    for man in humans:\n",
        "      # Сколько касок в пределах рамок человека (либо 1, либо 0)\n",
        "      helmet = 1 if len(helmets[(helmets[:, 0] >= man[0] - inter_helm) & (helmets[:, 1] >= man[1] - inter_helm) & \n",
        "                                (helmets[:, 2] <= man[2] + inter_helm) & (helmets[:, 3] <= man[3] + inter_helm)]) >= 1 else 0\n",
        "      # Сколько жилеток в пределах рамок человека (либо 1, либо 0)\n",
        "      vest = 1 if len(vests[(vests[:, 0] >= man[0] - inter_unif) & (vests[:, 1] >= man[1] - inter_unif) & \n",
        "                            (vests[:, 2] <= man[2] + inter_unif) & (vests[:, 3] <= man[3] + inter_unif)]) >= 1 else 0\n",
        "      #Это условие нужно для начала работы, потому что несколько первых кадров \n",
        "      #не имеют идентификатора. Можно отбросить первые кадры, здесь так и делается\n",
        "        # Это просто добавление в массив men. Часть параметров нужны нам дважды для выявления макс и мин.\n",
        "        # Поэтому дважды повторяются ордината низа и номер кадра\n",
        "      men = np.vstack((men, np.array([man[-2], \n",
        "                                        man[1], man[1],\n",
        "                                        man[3], man[3], \n",
        "                                        i, i,\n",
        "                                        helmet, vest])))\n",
        "      # Формируем датафрейм. Будем считать низ вначале и в конце, также первый кадр\n",
        "      # и последний кадр, где был этот id (пока это одно и тоже значение)\n",
        "  return men"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M252_JPWMWo"
      },
      "outputs": [],
      "source": [
        "# def get_count_men(n_count, men, orig_shape):# принимаем каличество кадров без детекции для переназначения id из Optuna\n",
        "# def get_count_men(men, orig_shape, barier, buff, tail):# принимаем барьериз Optuna\n",
        "# def get_count_men(tail, men, orig_shape):# определяем все сами\n",
        "# def get_count_men(men, orig_shape, buff):\n",
        "def get_count_men(men, orig_shape):# определяем все сами\n",
        "  n_ = int(max(men[:,0]))\n",
        "  orig_shape = int(orig_shape)\n",
        "  incoming = 0                                         # количество вошедших\n",
        "  exiting = 0                                        # количество вышедших\n",
        "  barier = 337\n",
        "  \n",
        "  gate_y = barier * orig_shape / 640 # определяем барьер сами\n",
        "\n",
        "\n",
        "  box_y_top     = [None] + [list() for _ in range(int(n_))]               \n",
        "  box_y_bottom  = [None] + [list() for _ in range(int(n_))]               \n",
        "  box_frame     = [None] + [list() for _ in range(int(n_))]\n",
        "               \n",
        "  \n",
        "\n",
        "\n",
        "  for i, m in enumerate(men):\n",
        "    id = int(m[0])\n",
        "    frame_n = int(m[-4])\n",
        "    y_top = float(m[2])\n",
        "    y_bottom = float(m[4])\n",
        "    box_y_top[id].append(y_top)\n",
        "    box_y_bottom[id].append(y_bottom)\n",
        "    box_frame[id].append(frame_n)\n",
        "\n",
        "    if len(box_frame[id]) > 11: # принудительно переназначаем айди на входе и выходе если треккер не переназначил\n",
        "      condition = box_frame[id][-1] - box_frame[id][-2] > 10 and ((box_y_top[id][-1] / orig_shape < 0.2) or (box_y_bottom[id][-1] / orig_shape > 0.8))\n",
        "                # условие смены id: \n",
        "                # верхняя граница бб в верхней части кадра  или нижняя граница бб в нижней части кадра\n",
        "                # бб не детектировался в течение 20 предыдущих кадров                             \n",
        "      if condition: \n",
        "        n_ += 1\n",
        "        box_y_top.append([])\n",
        "        box_y_bottom.append([])\n",
        "        box_frame.append([])\n",
        "        for j in range(i, len(men)):       \n",
        "          if men[j][0] == id:\n",
        "            men[j][0] = n_\n",
        "\n",
        "  if len(box_frame[id]) < 21: # удаляем айди чей трек короче n кадров\n",
        "    men = men[~np.isin(men[:,0], id)]\n",
        "\n",
        "  \n",
        "  n = int(max(men[:,0]))\n",
        "\n",
        "  human_c = [None] + [list() for _ in range(int(n))] \n",
        "  for m in men:\n",
        "    num = int(m[0])\n",
        "    box_center = (float(m[4]) - float(m[2]))/2+float(m[2])\n",
        "\n",
        "    # if float(m[1]) + tail* orig_shape / 640 < 640 * orig_shape / 640:\n",
        "    #   box_center = float(m[1]) +tail * orig_shape / 640\n",
        "    # else:\n",
        "    #   box_center = 640 * orig_shape / 640   \n",
        "\n",
        "    # box_center = float(m[1]) #+ 250.0 # берем не истинный центр бб а относительно головы потому что такой центр более устойчив и не прыгает\n",
        "    human_c[num].append(box_center)\n",
        "\n",
        "  ind = []\n",
        "  for i, h in enumerate(human_c):   \n",
        "\n",
        "    if h and h[0] < gate_y  < h[-1]:\n",
        "      incoming += 1\n",
        "      print(i, \"Вошел\") #отладка\n",
        "      ind.append(i)\n",
        "    elif h and h[0] > gate_y > h[-1]:\n",
        "      exiting += 1\n",
        "      print(i, \"Вышел\") #отладка\n",
        "      ind.append(i)\n",
        "\n",
        "    # if h and h[0] < gate_y  < h[-1] or h and h[0] < (gate_y-buff)  < h[-1]:\n",
        "    #   incoming += 1\n",
        "    # elif h and h[0] > gate_y > h[-1] or h and h[0] > (gate_y-buff) > h[-1]:\n",
        "    #   exiting += 1\n",
        "  men = men[np.isin(men[:,0], ind)]\n",
        "\n",
        "  \n",
        "  return men, incoming, exiting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNxIvUBIWMWq"
      },
      "outputs": [],
      "source": [
        "def get_count_vialotion(men, orig_shape): # step height определяем сами\n",
        "# def get_count_vialotion(men, orig_shape,step,height): # step height из optuna\n",
        "  orig_shape = int(orig_shape)\n",
        "  # format = orig_shape/640\n",
        "  # step = 46\n",
        "  # height = 200\n",
        "  df = pd.DataFrame(men, columns=['id', \n",
        "                                  'first_top_y', 'last_top_y', \n",
        "                                  'first_bottom_y','last_bottom_y', \n",
        "                                  'first_frame', 'last_frame', \n",
        "                                  'helmet', 'uniform'])\n",
        "  # Зададим правила агрегирующих функций\n",
        "  agg_func = {'first_top_y': 'first', 'last_top_y': 'last',\n",
        "              'first_bottom_y': 'first','last_bottom_y': 'last', \n",
        "              'first_frame': 'first', 'last_frame': 'last',\n",
        "              'helmet':'mean', 'uniform': 'mean' \n",
        "              }\n",
        "  # Группируем по id\n",
        "  df1 = df.groupby('id').agg(agg_func)\n",
        "  # Чтобы не выводилось предупреждение\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  # Определяем пройденное расстояние\n",
        "  # df1.loc[:, 'last_cent_y_stand'] = df1.last_top_y+height*format\n",
        "  # df1.loc[df1['last_cent_y_stand'] > orig_shape, \"last_cent_y_stand\"] = orig_shape # здесь считаем низ от макушки а не по низу бокса, фиксируем, но если он ниже размера картинки то лимитируем по низу картинки\n",
        "  # df1.loc[:, 'first_cent_y_stand'] = df1.first_top_y+height*format\n",
        "  # df1.loc[df1['first_cent_y_stand'] > orig_shape, \"first_cent_y_stand\"] = orig_shape # здесь считаем низ от макушки а не по низу бокса, фиксируем, но если он ниже размера картинки то лимитируем по низу картинки\n",
        "  df1.loc[:, 'distance'] = df1.last_bottom_y - df1.first_bottom_y\n",
        "  # df1.loc[:, 'distance'] = df1.last_bottom_y - df1.first_bottom_y\n",
        "  # df2 = df1.loc[(np.abs(df1.distance) > (step*format))] #здесь если человек вошел к турникету и вернулся ко входу то его дистанция будет около нуля и он отсеется, также как и охранник в обратном случае\n",
        "  df2 = df1.copy()\n",
        "  # Считаем входящих (сверху вниз)\n",
        "  incoming = df2.loc[df2.distance > 0].shape[0]\n",
        "  # Считаем выходящих\n",
        "  exiting = df2.loc[df2.distance < 0].shape[0]\n",
        "\n",
        "  V_helm = 0.15\n",
        "  V_unif = 0.5\n",
        "  dictinex = {'incoming':incoming , 'exiting': exiting}\n",
        "  df2.loc[df2.helmet < V_helm, 'helmet'] = 0\n",
        "  df2.loc[df2.helmet >= V_helm, 'helmet'] = 1\n",
        "  df2.loc[df2.uniform < V_unif, 'uniform'] = 0\n",
        "  df2.loc[df2.uniform >= V_unif, 'uniform'] = 1\n",
        "  \n",
        "  clothing_helmet =[] # соберем данные по одежде в отдельный массив для последующей проверки на этапе проверки P и R\n",
        "  clothing_unif =[]\n",
        "  for i, ds in enumerate(df2.values):\n",
        "    clothing_helmet.append(int(ds[6]))\n",
        "    clothing_unif.append(int(ds[7]))\n",
        "  violations = df2.loc[((df2.helmet == 0) | (df2.uniform == 0)), \n",
        "                     ['helmet', 'uniform', 'first_frame', 'last_frame']]   # а это сами нарушения с номерами кадров\n",
        "  # Можно отдельно отобрать три группы нарушителей, но здесь все вместе\n",
        "  # Пока только вывод на экран первых, можно сохранить в csv\n",
        "  # return men\n",
        "  return violations, incoming, exiting, df2, clothing_helmet, clothing_unif"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Отладка\n",
        "path = '/content/drive/MyDrive/best.pt/45/'   ## Модель\n",
        "tracker_path = 'ocsort00/'\n",
        "if not os.path.isdir(path+tracker_path):\n",
        "  os.makedirs(path+tracker_path)\n",
        "video_source ='/content/drive/MyDrive/dataset-v1.1/test/'\n",
        "\n",
        "tracker = OCSort(det_thresh = 0.49428431641933235, max_age = 7, # # 45 модель 2 ошибки\n",
        "                  min_hits = 7, iou_threshold = 0.6247364818234254, \n",
        "                  delta_t = 5, asso_func = 'iou', \n",
        "                  inertia = 0.6758806605183052, use_byte = True)\n",
        "\n",
        "for N in range(6,7): # устанавливаем какое видео смотрим\n",
        "  with open(path +f'{N}.npy', 'rb') as files:  #Загружаем объект содержащий формат исходного изображения и детекции\n",
        "    all_boxes_and_shp = np.load(files, allow_pickle=True)\n",
        "    orig_shp = all_boxes_and_shp[0] # Здесь формат\n",
        "    all_boxes = all_boxes_and_shp[1]  # Здесь боксы\n",
        "    out_boxes = tracking_on_detect(all_boxes,tracker, orig_shp)   # Отправляем боксы в трекинг + пробрасываем мимо трекинга каски и нетрекованные боксы людей\n",
        "    create_video_with_bbox(out_boxes, video_source + f'{N}.mp4', path + tracker_path + f'{N}_track.mp4') # функция отрисовки боксов на соответсвующем видео\n",
        "    # out_boxes_pd = pd.DataFrame(out_boxes)\n",
        "    men = get_men(out_boxes)   # Смотрим у какого айди есть каски и жилеты (по порогу от доли кадров где был зафиксирован айди человека + каска и жилет в его бб и без них)\n",
        "    men_clean, incoming1, exiting1 = get_count_men(men, orig_shp[1]) \n",
        "    # violation, incoming2, exiting2,df, clothing_helmet, clothing_unif = get_count_vialotion(men_clean, orig_shp[1]) # Здесь принимаем переназначенные айди смотрим нарушения а также повторно считаем входящих по дистанции, проверяем\n"
      ],
      "metadata": {
        "id": "CoO3EwP9ihh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73c840e-3d4f-4c84-fcc6-78b2a7750325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 Вышел\n",
            "6 Вышел\n",
            "7 Вышел\n",
            "10 Вышел\n",
            "14 Вошел\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzEuJ1SOV_RI"
      },
      "source": [
        "### Подсчет количества людей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwWWXH92dqt3"
      },
      "outputs": [],
      "source": [
        "#Истинные значения вошедших и вышедших на видео\n",
        "dict_in_true =  {'1':3,'2':3,'3':3,'4':4,'5':0,'6':1,'7':0,'8':0,'9':1,'10':0,'11':0,'12':0,'13':2,'14':0,'15':2,'16':0,'17':0,'18':4,'19':1,'20':0,'21':1,'22':0,'23':0,'24':1,'25':2,'26':0,'27':1,'28':1,'29':1,'30':1,'31':0,'32':0,'33':0,'34':0,'35':0,'36':0,'37':0,'38':8,'39':0,'40':0,'41':0,'42':2,'43':0}  # 20 видео битое с невошедшим призраком (человек раздвоился)\n",
        "dict_out_true = {'1':0,'2':0,'3':0,'4':0,'5':0,'6':4,'7':4,'8':5,'9':1,'10':2,'11':3,'12':4,'13':4,'14':3,'15':0,'16':4,'17':6,'18':0,'19':0,'20':0,'21':1,'22':3,'23':1,'24':0,'25':0,'26':1,'27':1,'28':1,'29':1,'30':3,'31':2,'32':0,'33':0,'34':0,'35':0,'36':0,'37':0,'38':7,'39':1,'40':1,'41':0,'42':0,'43':0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUOCmhKsWMWr"
      },
      "outputs": [],
      "source": [
        "def compare_dict(d1,d2): #функция сравнения словарей входящих/выходящих предсказанных с эталонным словарем\n",
        "  dict_all ={}\n",
        "  d_1 = set(d1.keys())\n",
        "  d_2 = set(d2.keys())\n",
        "  common_keys = d_1.intersection(d_2)\n",
        "  \n",
        "  if common_keys:\n",
        "    dict_all = {k: d1[k] - d2[k] for k in common_keys}\n",
        "  return dict_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0uNX2nbrF_-",
        "outputId": "9403b52f-3fd2-4938-963b-95e6362a3f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "данные по видео 32: отсутствуют\n",
            "данные по видео 33: отсутствуют\n",
            "данные по видео 34: отсутствуют\n",
            "данные по видео 35: отсутствуют\n",
            "данные по видео 37: отсутствуют\n",
            "данные по видео 41: отсутствуют\n",
            "данные по видео 43: отсутствуют\n",
            "суммарное количество ошибок первого алгоритма на входящих  0\n",
            "в видео 17 выходящих 6 а не 5\n",
            "в видео 16 выходящих 4 а не 3\n",
            "суммарное количество ошибок первого алгоритма на выходящих 2\n",
            "суммарное количество ошибок второго алгоритма на входящих  0\n",
            "в видео 17 выходящих 6 а не 5\n",
            "в видео 16 выходящих 4 а не 3\n",
            "суммарное количество ошибок второго алгоритма на выходящих 2\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/best.pt/45/'   ## Модель\n",
        "tracker_path = 'ocsort00/'\n",
        "if not os.path.isdir(path+tracker_path):\n",
        "  os.makedirs(path+tracker_path)\n",
        "video_source ='/content/drive/MyDrive/dataset-v1.1/test/' # папка с исходными видео для отрисовки готовых боксов\n",
        "\n",
        "tracker = OCSort(det_thresh = 0.49428431641933235, max_age = 7, # # 45 модель 2 ошибки\n",
        "                  min_hits = 7, iou_threshold = 0.6247364818234254, \n",
        "                  delta_t = 5, asso_func = 'iou', \n",
        "                  inertia = 0.6758806605183052, use_byte = True)\n",
        "\n",
        "\n",
        "# # # создаем пустые словари которые будем наполнять предсказаниями вошедших /вышедших первым  и вторым алгоритмом\n",
        "d_in1 = {str(n): 0 for n in list(range(1,44))} \n",
        "d_out1 = {str(n): 0 for n in list(range(1,44))}\n",
        "d_in2 = {str(n): 0 for n in list(range(1,44))} \n",
        "d_out2 = {str(n): 0 for n in list(range(1,44))}\n",
        "\n",
        "# # создаем пустые словари которые будем наполнять предсказаниями нарушениями по каске (используются в следующем разделе)\n",
        "# # создаем пустые словари которые будем наполнять предсказаниями нарушениями по униформе (используются в следующем разделе)\n",
        "d_helmet = {str(n): [] for n in list(range(1,44))} \n",
        "d_unif = {str(n): [] for n in list(range(1,44))} \n",
        "\n",
        "for N in range(1,44): # устанавливаем какое видео смотрим\n",
        "    try:\n",
        "        with open(path +f'{N}.npy', 'rb') as files:  #Загружаем объект содержащий формат исходного изображения и детекции\n",
        "          all_boxes_and_shp = np.load(files, allow_pickle=True)\n",
        "          orig_shp = all_boxes_and_shp[0] # Здесь формат\n",
        "          all_boxes = all_boxes_and_shp[1]  # Здесь боксы\n",
        "          out_boxes = tracking_on_detect(all_boxes,tracker, orig_shp)   # Отправляем боксы в трекинг + пробрасываем мимо трекинга каски и нетрекованные боксы людей\n",
        "          create_video_with_bbox(out_boxes, video_source + f'{N}.mp4', path + tracker_path + f'{N}_track.mp4') # функция отрисовки боксов на соответсвующем видео\n",
        "          # out_boxes_pd = pd.DataFrame(out_boxes)\n",
        "          # out_boxes_pd.to_excel(path + tracker_path + f\"df_{N}_{round(orig_shp[1])}_.xlsx\") # сохраняем что бы было)\n",
        "          men = get_men(out_boxes)   # Смотрим у какого айди есть каски и жилеты (по порогу от доли кадров где был зафиксирован айди человека + каска и жилет в его бб и без них)\n",
        "          men_clean, incoming1, exiting1 = get_count_men(men, orig_shp[1]) # здесь переназначаем айди входящий/выходящий (временное решение для MVP, надо думать над продом)\n",
        "          violation, incoming2, exiting2,df, clothing_helmet, clothing_unif = get_count_vialotion(men_clean, orig_shp[1]) # Здесь принимаем переназначенные айди смотрим нарушения а также повторно считаем входящих по дистанции, проверяем\n",
        "\n",
        "          d_in1[f'{N}'] = incoming1\n",
        "          d_out1[f'{N}'] = exiting1\n",
        "          d_in2[f'{N}'] = incoming2\n",
        "          d_out2[f'{N}'] = exiting2\n",
        "          d_helmet[f'{N}'] = clothing_helmet         \n",
        "          d_unif[f'{N}'] = clothing_unif       \n",
        "\n",
        "    except:    \n",
        "        print(f'данные по видео {N}: отсутствуют')\n",
        "\n",
        "# # Далее модуль распечатки данных\n",
        "d_in_comp = compare_dict(d_in1, dict_in_true)\n",
        "for key, value in d_in_comp.items(): \n",
        "  if value != 0:\n",
        "    print(f'в видео {key} входящих {dict_in_true[key]} а не {d_in1[key]}')\n",
        "print(f'суммарное количество ошибок первого алгоритма на входящих  {sum(abs(ele) for ele in d_in_comp.values())}')\n",
        "\n",
        "d_out_comp = compare_dict(d_out1, dict_out_true)\n",
        "for key, value in d_out_comp.items(): \n",
        "  if value != 0:\n",
        "    print(f'в видео {key} выходящих {dict_out_true[key]} а не {d_out1[key]}')\n",
        "print(f'суммарное количество ошибок первого алгоритма на выходящих {sum(abs(ele) for ele in d_out_comp.values())}')\n",
        "\n",
        "d_in_comp = compare_dict(d_in2, dict_in_true)\n",
        "for key, value in d_in_comp.items(): \n",
        "  if value != 0:\n",
        "    print(f'в видео {key} входящих {dict_in_true[key]} а не {d_in2[key]}')\n",
        "print(f'суммарное количество ошибок второго алгоритма на входящих  {sum(abs(ele) for ele in d_in_comp.values())}')\n",
        "\n",
        "d_out_comp = compare_dict(d_out2, dict_out_true)\n",
        "for key, value in d_out_comp.items(): \n",
        "  if value != 0:\n",
        "    print(f'в видео {key} выходящих {dict_out_true[key]} а не {d_out2[key]}')\n",
        "print(f'суммарное количество ошибок второго алгоритма на выходящих {sum(abs(ele) for ele in d_out_comp.values())}')\n",
        "\n",
        "d_in_comp = compare_dict(d_in2, dict_in_true) #суммарное количество ошибок первого алгоритма на входящих  \n",
        "d_out_comp = compare_dict(d_out2, dict_out_true) # суммарное количество ошибок первого алгоритма на выходящих \n",
        "d_comp = sum(abs(ele) for ele in d_in_comp.values()) + sum(abs(ele) for ele in d_out_comp.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We1jVACPJqy7"
      },
      "source": [
        "### Оптимизация  кол-ва людей Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYDw-F3nJqy8",
        "outputId": "249bc292-d020-40a1-d115-f54abc3eb32f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rjPcapiqJqy-",
        "outputId": "f6e84fb7-5058-4d39-d580-07329a2e609f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.1.1'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "optuna.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ9fQoJBfQ4I"
      },
      "outputs": [],
      "source": [
        "# yaml2 ={  asso_func: giou\n",
        "#   conf_thres: 0.5122620708221085\n",
        "#   delta_t: 1\n",
        "#   det_thresh: 0\n",
        "#   inertia: 0.3941737016672115\n",
        "#   iou_thresh: 0.22136877277096445\n",
        "#   max_age: 50\n",
        "#   min_hits: 1\n",
        "#   use_byte: false} # микель 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usgJUXt63D9Y"
      },
      "outputs": [],
      "source": [
        "# # 45 модель 2 алгоритм 6 ошибок\n",
        "  # tracker = OCSort(det_thresh = 0.5972122815852265, max_age = 7,\n",
        "  #                 min_hits = 5, iou_threshold = 0.1330893701047955, \n",
        "  #                 delta_t = 2, asso_func = 'iou', \n",
        "  #                 inertia = 0.2407496403510045, use_byte = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bz8Nuhfz1h5"
      },
      "outputs": [],
      "source": [
        "# # 45 модель 1 алгоритм барьер 337 2 ошибки\n",
        "  # tracker = OCSort(det_thresh = 0.49428431641933235, max_age = 7, # # 45 модель 2 ошибки\n",
        "  #                 min_hits = 7, iou_threshold = 0.6247364818234254, \n",
        "  #                 delta_t = 5, asso_func = 'iou', \n",
        "  #                 inertia = 0.6758806605183052, use_byte = True)\n",
        "# {'det_thresh': 0.4862688342603671, 'max_age': 7.456359330880515, 'min_hits': 6.084068672838238, 'iou_threshold': 0.6268883790023444, 'delta_t': 5.984993700881928, 'asso': 'iou', 'inertia': 0.6557787153239634, 'use_byte': True, 'barier': 336}. \n",
        "# {'det_thresh': 0.46648242342039237, 'max_age': 7.203196769474859, 'min_hits': 6.433879332154186, 'iou_threshold': 0.6305934741741774, 'delta_t': 5.381967701269865, 'asso': 'iou', 'inertia': 0.6369425863377747, 'use_byte': True, 'barier': 337}. \n",
        "# {'det_thresh': 0.49428431641933235, 'max_age': 6.910533298012, 'min_hits': 6.535011489592976, 'iou_threshold': 0.6247364818234254, 'delta_t': 5.248070195914983, 'asso': 'iou', 'inertia': 0.6758806605183052, 'use_byte': True, 'barier': 340}. \n",
        "# {'det_thresh': 0.4800010924947306, 'max_age': 7.616682342988325, 'min_hits': 6.235897942703035, 'iou_threshold': 0.6203530097118262, 'delta_t': 5.516049204278155, 'asso': 'iou', 'inertia': 0.6463059396477179, 'use_byte': True, 'barier': 339}. \n",
        "# {'det_thresh': 0.4581106410893448, 'max_age': 7.0674184728269385, 'min_hits': 6.234815471224487, 'iou_threshold': 0.6290289995639651, 'delta_t': 5.034286694675483, 'asso': 'iou', 'inertia': 0.6385260183285119, 'use_byte': True, 'barier': 339}. \n",
        "# {'det_thresh': 0.46225643518026666, 'max_age': 7.036458426921717, 'min_hits': 6.3261509842693116, 'iou_threshold': 0.6262538211501386, 'delta_t': 5.003513218268599, 'asso': 'iou', 'inertia': 0.6287646232751898, 'use_byte': True, 'barier': 338}. \n",
        "# # 45 модель 4 ошибки\n",
        "# {'det_thresh': 0.5413427615421595, 'max_age': 7.379847519608593, 'min_hits': 6.804953426768252, 'iou_threshold': 0.6406466166134259, 'delta_t': 6.955562247157338, 'asso': 'iou', 'inertia': 0.7246055201833036, 'use_byte': True, 'barier': 335}\n",
        "# {'det_thresh': 0.3776929765510213, 'max_age': 7.7378061293440785, 'min_hits': 6.40569787806849, 'iou_threshold': 0.6468340994720151, 'delta_t': 5.398816334493228, 'asso': 'iou', 'inertia': 0.6616686833612563, 'use_byte': True, 'barier': 334}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He0OwNvRTrkp",
        "outputId": "29d6a346-4562-4da2-c2d5-1b78ba3b692c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-11 12:17:27,427]\u001b[0m A new study created in memory with name: no-name-33677a6a-f390-4979-9ce2-99dbc1b8ea71\u001b[0m\n",
            "\u001b[32m[I 2023-04-11 12:18:13,538]\u001b[0m Trial 0 finished with value: 11.0 and parameters: {'step': 15, 'height': 415}. Best is trial 0 with value: 11.0.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "def objective(trial):\n",
        "  path = '/content/drive/MyDrive/best.pt/45/'   ## Модель   \n",
        "  path = path\n",
        "  tracker_path = '/ocsort00/' # default\n",
        "  seed = 123\n",
        "  # det_thresh = trial.suggest_float('det_thresh', 0.05, 0.95, log=True) # ШИРОКИЙ ДИАПАЗОН\n",
        "  # max_age= int(trial.suggest_float('max_age', 5, 70, log=True)) # 30\n",
        "  # min_hits= int(trial.suggest_float('min_hits', 1, 10, log=True)) # 1\n",
        "  # iou_threshold = trial.suggest_float('iou_threshold', 0.05, 0.95, log=True) \n",
        "  # delta_t= int(trial.suggest_float('delta_t', 1, 10, log=True)) # 1  \n",
        "  # asso_func= trial.suggest_categorical('asso_func', [\"iou\",\"giou\",\"ciou\",\"diou\",\"ct_dist\"]) #\n",
        "  # inertia=trial.suggest_float('inertia', 0.05, 0.95, log=True) # \n",
        "  # use_byte=trial.suggest_categorical('use_byte', [False,True]) #\n",
        "  # step = trial.suggest_int('step', 20, 150, log=True)\n",
        "  # height = trial.suggest_int('height', 100, 350, log=True)\n",
        "\n",
        "\n",
        "  \n",
        "  # det_thresh = trial.suggest_float('det_thresh', 0.36, 0.56, log=True) # узкий диапазон на 45 модель \n",
        "  # max_age= int(trial.suggest_float('max_age', 6, 8, log=True)) # \n",
        "  # min_hits= int(trial.suggest_float('min_hits', 6, 8, log=True)) # \n",
        "  # iou_threshold = trial.suggest_float('iou_threshold', 0.62, 0.66, log=True) \n",
        "  # delta_t= int(trial.suggest_float('delta_t', 5, 8, log=True)) #   \n",
        "  # asso_func= trial.suggest_categorical('asso_func', [\"iou\"]) \n",
        "  # inertia=trial.suggest_float('inertia', 0.6, 0.75, log=True) \n",
        "  # use_byte=trial.suggest_categorical('use_byte', [True]) \n",
        "  # barier = trial.suggest_int('barier', 330, 340, log=True)\n",
        "\n",
        "\n",
        "  step = trial.suggest_int('step', 15, 60, log=True)\n",
        "  height = trial.suggest_int('height', 200, 450, log=True)  \n",
        "  # barier = trial.suggest_int('barier', 300, 400, log=True)\n",
        "  # buff = trial.suggest_int('buff', 5, 70, log=True)\n",
        "  # tail = trial.suggest_int('tail', 150, 250, log=True)\n",
        "\n",
        "  \n",
        "  tracker = OCSort(det_thresh = 0.49428431641933235, max_age = 7, # # 45 модель 2 ошибки\n",
        "                  min_hits = 7, iou_threshold = 0.6247364818234254, \n",
        "                  delta_t = 5, asso_func = 'iou', \n",
        "                  inertia = 0.6758806605183052, use_byte = True)\n",
        "\n",
        "  # tracker = OCSort(det_thresh = det_thresh,max_age = max_age, min_hits = min_hits,\n",
        "  #                  iou_threshold = iou_threshold, delta_t = delta_t, asso_func= asso_func,\n",
        "  #                  inertia = inertia, use_byte = use_byte)\n",
        "\n",
        "\n",
        "\n",
        "  # создаем пустые словари которые будем наполнять предсказаниями вошедших /вышедших первым  и вторым алгоритмом\n",
        "  d_in1 = {str(n): 0 for n in list(range(1,44))} \n",
        "  d_out1 = {str(n): 0 for n in list(range(1,44))}\n",
        "  d_in2 = {str(n): 0 for n in list(range(1,44))} \n",
        "  d_out2 = {str(n): 0 for n in list(range(1,44))}\n",
        "\n",
        "  # создаем пустые словари которые будем наполнять предсказаниями нарушениями по каске (используются в следующем разделе)\n",
        "  # создаем пустые словари которые будем наполнять предсказаниями нарушениями по униформе (используются в следующем разделе)\n",
        "  d_helmet = {str(n): [] for n in list(range(1,44))} \n",
        "  d_unif = {str(n): [] for n in list(range(1,44))} \n",
        "\n",
        "  for N in range(1,44): # устанавливаем какое видео смотрим\n",
        "      try:\n",
        "          with open(path+f'{N}.npy', 'rb') as files:  #Загружаем объект содержащий формат исходного изображения и детекции\n",
        "            all_boxes_and_shp = np.load(files, allow_pickle=True)\n",
        "            orig_shp = all_boxes_and_shp[0] # Здесь формат\n",
        "            all_boxes = all_boxes_and_shp[1]  # Здесь боксы\n",
        "            out_boxes, bbox = tracking_on_detect(all_boxes,tracker, orig_shp)   # Отправляем боксы в трекинг + пробрасываем мимо трекинга каски и нетрекованные боксы людей\n",
        "            out_boxes_pd = pd.DataFrame(out_boxes)\n",
        "            # out_boxes_pd.to_excel(path + tracker_path + f\"df_{N}_{round(orig_shp[1])}_.xlsx\") # сохраняем что бы было)\n",
        "            men = get_men(out_boxes)   # Смотрим у какого айди есть каски и жилеты (по порогу от доли кадров где был зафиксирован айди человека + каска и жилет в его бб и без них)\n",
        "            men_clean, incoming1, exiting1 = get_count_men(men, orig_shp[1]) # здесь переназначаем айди входящий/выходящий (временное решение для MVP, надо думать над продом)\n",
        "            violation, incoming2, exiting2,df, clothing_helmet, clothing_unif = get_count_vialotion(men_clean, orig_shp[1],step,height) # Здесь принимаем переназначенные айди смотрим нарушения а также повторно считаем входящих по дистанции, проверяем\n",
        "\n",
        "            d_in1[f'{N}'] = incoming1\n",
        "            d_out1[f'{N}'] = exiting1\n",
        "            d_in2[f'{N}'] = incoming2\n",
        "            d_out2[f'{N}'] = exiting2\n",
        "            d_helmet[f'{N}'] = clothing_helmet         \n",
        "            d_unif[f'{N}'] = clothing_unif       \n",
        "\n",
        "      except:    \n",
        "          pass\n",
        "\n",
        "    # Далее модуль распечатки данных\n",
        "  d_in_comp = compare_dict(d_in2, dict_in_true) #суммарное количество ошибок первого алгоритма на входящих  \n",
        "  d_out_comp = compare_dict(d_out2, dict_out_true) # суммарное количество ошибок первого алгоритма на выходящих \n",
        "  d_comp = sum(abs(ele) for ele in d_in_comp.values()) + sum(abs(ele) for ele in d_out_comp.values())\n",
        "  # print(f'суммарное количество ошибок первого алгоритма  {d_comp}')\n",
        "  return d_comp\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Количество нарушений минимальное: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT6enxDcJqzG"
      },
      "source": [
        "### Plotting the study\n",
        "\n",
        "Plotting the optimization history of the study."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "lsJ2LmzVJqzH",
        "outputId": "d71f75da-96c1-40a6-9a96-83f06fa07e61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"1b816dab-25f7-42cc-bd17-dfda0b9a2638\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1b816dab-25f7-42cc-bd17-dfda0b9a2638\")) {                    Plotly.newPlot(                        \"1b816dab-25f7-42cc-bd17-dfda0b9a2638\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[18.0,14.0,14.0,14.0,15.0,13.0,15.0,18.0,13.0,18.0,15.0,13.0,13.0,13.0,14.0,14.0,17.0,14.0,14.0,14.0,13.0,13.0,14.0,13.0,14.0,14.0,13.0,15.0,13.0,16.0],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[18.0,14.0,14.0,14.0,14.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0,13.0],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1b816dab-25f7-42cc-bd17-dfda0b9a2638');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVdE7IYMJqzH"
      },
      "source": [
        "Plotting the accuracies for each hyperparameter for each trial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0KUvBnldJqzI",
        "outputId": "12e17d59-ef8e-4e1b-ccc2-3206e83ce17b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"924d62fb-fc8e-4bcf-9836-82f8ab931ac4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"924d62fb-fc8e-4bcf-9836-82f8ab931ac4\")) {                    Plotly.newPlot(                        \"924d62fb-fc8e-4bcf-9836-82f8ab931ac4\",                        [{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5}},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.4268490990522868,0.21371557493513174,0.18448427513189972,0.17790207176043268,0.14773920645730632,0.27744234640210186,0.12912306492214567,0.3769516556879642,0.24962916776546842,0.3745020412347999,0.10017430614875353,0.2777220644611452,0.27178073549111714,0.277455068740188,0.23370352450316595,0.3249629973948557,0.4905372912578013,0.23755417627574238,0.3108468418125604,0.19530381125080495,0.24637120644583133,0.28534856251754237,0.31538170046766906,0.25507867031621473,0.2327212161050549,0.21020631188363695,0.275500256838315,0.34090215014267755,0.298592746796422,0.3578194528117919],\"y\":[18.0,14.0,14.0,14.0,15.0,13.0,15.0,18.0,13.0,18.0,15.0,13.0,13.0,13.0,14.0,14.0,17.0,14.0,14.0,14.0,13.0,13.0,14.0,13.0,14.0,14.0,13.0,15.0,13.0,16.0],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Slice Plot\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"iou_threshold\"},\"type\":\"log\"},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('924d62fb-fc8e-4bcf-9836-82f8ab931ac4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_slice(study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66AKT_TWJqzI"
      },
      "source": [
        "Plotting the accuracy surface for the hyperparameters involved in the random forest model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwsqLbtdJqzJ"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_contour(study, params=['n_estimators', 'max_depth'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJublwU0Vqlw"
      },
      "source": [
        "### Нарушения на видео"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2pNEEqtVpU0"
      },
      "outputs": [],
      "source": [
        "#Истинные значения нарушений на видео\n",
        "d_true_helmet = {'1': [1, 1, 1], '2': [0, 1, 1], '3': [1, 0, 1], '4': [1, 0, 1, 1], '5': [], '6': [0, 0, 0, 0, 1], '7': [0, 0, 0, 0], '8': [0, 0, 0, 0, 0], '9': [0, 1], '10': [0, 0], '11': [0, 0, 0], '12': [0, 0, 0, 1], '13': [1, 0, 0, 0, 0, 0], '14': [1, 1, 1], '15': [0, 0], '16': [0, 0, 1, 0], '17': [0, 1, 0, 0, 0, 0], '18': [1, 1, 1, 1], '19': [0], '20': [], '21': [0,0], '22': [0, 1, 0], '23': [0], '24': [1], '25': [0, 0], '26': [0], '27': [0, 1], '28': [0, 1], '29': [0, 0], '30': [0, 0, 0, 0], '31': [1, 1], '32': [], '33': [], '34': [], '35': [], '36': [], '37': [], '38': [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1], '39': [1], '40': [0], '41': [], '42': [0, 0], '43': []} # 20 видео битое с невошедшим призраком (человек раздвоился)\n",
        "d_true_unif = {'1': [1, 1, 1], '2': [1, 1, 1], '3': [1, 0, 1], '4': [1, 0, 1, 1], '5': [], '6': [0, 0, 0, 0, 1], '7': [1, 0, 1, 0], '8': [0, 0, 0, 0, 0], '9': [1, 1], '10': [1, 1], '11': [0, 0, 1], '12': [0, 0, 0, 1], '13': [1, 1, 0, 0, 1, 1], '14': [1, 1, 1], '15': [0, 0], '16': [1, 1, 1, 0], '17': [0, 1, 0, 0, 1, 1], '18': [1, 1, 0, 0], '19': [1], '20': [], '21': [0,0], '22': [0, 1, 0], '23': [0], '24': [1], '25': [0, 0], '26': [0], '27': [0, 1], '28': [0, 1], '29': [0, 0], '30': [0, 1, 1, 1], '31': [1, 1], '32': [], '33': [], '34': [], '35': [], '36': [], '37': [], '38': [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1], '39': [1], '40': [0], '41': [], '42': [0, 0], '43': []} # 20 видео битое с невошедшим призраком (человек раздвоился)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liNZEkpZ7h8H",
        "outputId": "13bd57f1-aeef-4eb2-f872-5d6a439412c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'1': [1, 0, 0], '2': [1, 1, 0, 0, 0, 0], '3': [1, 0, 2, 2], '4': [1, 1, 0, 2]}\n",
            "{'1': [1, 1, 2], '2': [1, 1, 0, 0, 2, 2], '3': [1, 1, 0, 0], '4': [1, 1, 0, 0]}\n"
          ]
        }
      ],
      "source": [
        "\"\"\" \n",
        "Эта функция выравнивает длину массива в нарушениях по каждому видео так что бы подать в метрику sklearn массивы одной длины\n",
        "Делает она это следующим образом: \n",
        "- Создаются копии массивов с эталоном и предсказанием\n",
        "- Изменению подвергаются только те массивы (их копии) по видео в которых количество айди предсказанных отличается от эталонного !!!(их всего 1-2)!!!\n",
        "В других массивах ничего менять не нужно потому что порядок в котором айди попадают в предсказания совпадает с эталоном \n",
        "(проверено в ручную на нескольких экспериментах)\n",
        "- Копии этих массивов сортируются от 1 к 0 и там где не хватает значений добавляются маркеры отсутсвия детекции или доп детекции в случае эталона\n",
        "( двойки - это третий класс снижающий P R для наших двух нарушения/ненарушения) \n",
        "Таким образом мы выравниваем длины массивов\n",
        "\n",
        "\n",
        "Идея заключается в том что нам нужно при вычислении метрик подать пары значений и главное подать ту пару где у нас происходит отличие предсказания от эталона\n",
        "Т.е. если предсказание определило 3 человека в касках а реально их было 4, то мы добьем четвертое значение двойкой и не важно какой из них не задетектровался\n",
        "!!!Ситуация при которой два человека в эталоне по форме определились предиктом как один одетый по форме также будет штрафоваться добавлением двойки к массиву т.к. \n",
        "в противном случае это могло быть и два человека одетых по разному (один правильно - а другой нет) и обработка этого могла не заметить!!! \n",
        "\n",
        "Все обратные логики также справедливы!\n",
        "\n",
        "Подход в рамках имеющихся тестовых видео работает (проверялось вручную на нашей пособработке по всем видео)\n",
        "\n",
        "Возможно для цели подбора треккера с максимальной P метрикой по единицам логику нужно перевернуть и сортировать от меньшего к большему, добивать единицами - !Вернуться!\n",
        "\n",
        "Ниже после формулы приведена демонстрация\n",
        "\"\"\"\n",
        "\n",
        "def dict_fill(d_pred_, d_true_):  # функция которая выравнивает содержимое в предсказанном словаре с эталоно заполняя его 0\n",
        "  d_pred_exp = d_pred_.copy()  # создаем новые словари\n",
        "  d_true_exp = d_true_.copy()\n",
        "  if len(d_pred_exp) != len(d_true_exp): # если длина значений словарей не совпадает делаем соритрировку от 1 к 0 и добиваем  значения словаря меньшео размера маркером отсутсвия детекции - 2\n",
        "    d_pred_exp.sort(reverse = True)\n",
        "    d_true_exp.sort(reverse = True)\n",
        "    _list = [d_pred_exp,d_true_exp]\n",
        "    for a in _list:\n",
        "      a.extend([2] * (max(map(len, _list)) - len(a)))\n",
        "\n",
        "  return d_pred_exp, d_true_exp\n",
        "\n",
        "### Демонстрация!\n",
        "d_pred = {'1': [1, 0, 0], '2': [1, 0, 0, 0, 1, 0],  '3': [1, 0],        '4': [1, 0, 1]} # 1 - одного одетого задетектил как двоих раздетых 2 - лишние треки в середине видео 3 - пропуск отсутсвие детекции в конце 4 -объеденил в середине\n",
        "d_true = {'1': [1, 1],    '2': [1, 0, 1, 0],        '3': [1, 0, 0, 1],  '4': [1, 0, 0, 1]}\n",
        "for i in range(1,5):\n",
        "  d_pred[f'{i}'], d_true[f'{i}'] = dict_fill(d_pred[f'{i}'], d_true[f'{i}'])\n",
        "print(d_pred)\n",
        "print(d_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK4IHsXxQ0UN",
        "outputId": "f95074ef-8d01-4577-9711-e0da04905ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "данные по видео 32: отсутствуют\n",
            "данные по видео 33: отсутствуют\n",
            "данные по видео 34: отсутствуют\n",
            "данные по видео 35: отсутствуют\n",
            "данные по видео 37: отсутствуют\n",
            "данные по видео 41: отсутствуют\n",
            "данные по видео 43: отсутствуют\n",
            "суммарное количество ошибок первого алгоритма на входящих  0\n",
            "в видео 17 выходящих 6 а не 5\n",
            "в видео 16 выходящих 4 а не 3\n",
            "суммарное количество ошибок первого алгоритма на выходящих 2\n",
            "суммарное количество ошибок второго алгоритма на входящих  0\n",
            "в видео 17 выходящих 6 а не 5\n",
            "в видео 16 выходящих 4 а не 3\n",
            "суммарное количество ошибок второго алгоритма на выходящих 2\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/best.pt/45/'   ## Модель   \n",
        "path = path\n",
        "tracker_path = '/ocsort00/' # default\n",
        "\n",
        "tracker = OCSort(det_thresh = 0.49428431641933235, max_age = 7, # # 45 модель 2 ошибки\n",
        "                  min_hits = 7, iou_threshold = 0.6247364818234254, \n",
        "                  delta_t = 5, asso_func = 'iou', \n",
        "                  inertia = 0.6758806605183052, use_byte = True)\n",
        "\n",
        "\n",
        "# # # создаем пустые словари которые будем наполнять предсказаниями вошедших /вышедших первым  и вторым алгоритмом\n",
        "d_in1 = {str(n): 0 for n in list(range(1,44))} \n",
        "d_out1 = {str(n): 0 for n in list(range(1,44))}\n",
        "d_in2 = {str(n): 0 for n in list(range(1,44))} \n",
        "d_out2 = {str(n): 0 for n in list(range(1,44))}\n",
        "\n",
        "# # создаем пустые словари которые будем наполнять предсказаниями нарушениями по каске (используются в следующем разделе)\n",
        "# # создаем пустые словари которые будем наполнять предсказаниями нарушениями по униформе (используются в следующем разделе)\n",
        "d_helmet = {str(n): [] for n in list(range(1,44))} \n",
        "d_unif = {str(n): [] for n in list(range(1,44))} \n",
        "\n",
        "for N in range(1,44): # устанавливаем какое видео смотрим\n",
        "    try:\n",
        "        with open(path +f'{N}.npy', 'rb') as files:  #Загружаем объект содержащий формат исходного изображения и детекции\n",
        "          all_boxes_and_shp = np.load(files, allow_pickle=True)\n",
        "          orig_shp = all_boxes_and_shp[0] # Здесь формат\n",
        "          all_boxes = all_boxes_and_shp[1]  # Здесь боксы\n",
        "          out_boxes,bbox = tracking_on_detect(all_boxes,tracker, orig_shp)   # Отправляем боксы в трекинг + пробрасываем мимо трекинга каски и нетрекованные боксы людей\n",
        "          out_boxes_pd = pd.DataFrame(out_boxes)\n",
        "          # out_boxes_pd.to_excel(path + tracker_path + f\"df_{N}_{round(orig_shp[1])}_.xlsx\") # сохраняем что бы было)\n",
        "          men = get_men(out_boxes)   # Смотрим у какого айди есть каски и жилеты (по порогу от доли кадров где был зафиксирован айди человека + каска и жилет в его бб и без них)\n",
        "          men_clean, incoming1, exiting1 = get_count_men(men, orig_shp[1]) # здесь переназначаем айди входящий/выходящий (временное решение для MVP, надо думать над продом)\n",
        "          violation, incoming2, exiting2,df, clothing_helmet, clothing_unif = get_count_vialotion(men_clean, orig_shp[1]) # Здесь принимаем переназначенные айди смотрим нарушения а также повторно считаем входящих по дистанции, проверяем\n",
        "\n",
        "          d_in1[f'{N}'] = incoming1\n",
        "          d_out1[f'{N}'] = exiting1\n",
        "          d_in2[f'{N}'] = incoming2\n",
        "          d_out2[f'{N}'] = exiting2\n",
        "          d_helmet[f'{N}'] = clothing_helmet         \n",
        "          d_unif[f'{N}'] = clothing_unif       \n",
        "\n",
        "    except:    \n",
        "        print(f'данные по видео {N}: отсутствуют')\n",
        "\n",
        "# # Далее модуль распечатки данных\n",
        "d_in_comp = compare_dict(d_in1, dict_in_true)\n",
        "for key, value in d_in_comp.items(): \n",
        "  if value != 0:\n",
        "    print(f'в видео {key} входящих {dict_in_true[key]} а не {d_in1[key]}')\n",
        "print(f'суммарное количество ошибок первого алгоритма на входящих  {sum(abs(ele) for ele in d_in_comp.values())}')\n",
        "\n",
        "d_out_comp = compare_dict(d_out1, dict_out_true)\n",
        "for key, value in d_out_comp.items(): \n",
        "  if value != 0:\n",
        "    print(f'в видео {key} выходящих {dict_out_true[key]} а не {d_out1[key]}')\n",
        "print(f'суммарное количество ошибок первого алгоритма на выходящих {sum(abs(ele) for ele in d_out_comp.values())}')\n",
        "\n",
        "d_in_comp = compare_dict(d_in2, dict_in_true)\n",
        "for key, value in d_in_comp.items(): \n",
        "  if value != 0:\n",
        "    print(f'в видео {key} входящих {dict_in_true[key]} а не {d_in2[key]}')\n",
        "print(f'суммарное количество ошибок второго алгоритма на входящих  {sum(abs(ele) for ele in d_in_comp.values())}')\n",
        "\n",
        "d_out_comp = compare_dict(d_out2, dict_out_true)\n",
        "for key, value in d_out_comp.items(): \n",
        "  if value != 0:\n",
        "    print(f'в видео {key} выходящих {dict_out_true[key]} а не {d_out2[key]}')\n",
        "print(f'суммарное количество ошибок второго алгоритма на выходящих {sum(abs(ele) for ele in d_out_comp.values())}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uxM1xSyVWj7"
      },
      "outputs": [],
      "source": [
        "# т.к. словари при подгонке размерности видоизменяются создаем новые что бы не потерять старые \n",
        "d_true_helmet_exp = {str(n): [] for n in list(range(1,44))}\n",
        "d_helmet_exp = {str(n): [] for n in list(range(1,44))}  \n",
        "d_true_unif_exp = {str(n): [] for n in list(range(1,44))} \n",
        "d_unif_exp = {str(n): [] for n in list(range(1,44))} \n",
        "\n",
        "# Проходимся по всем словарям с нарушениями и эталонным словарям и выравниваем их\n",
        "for N in range(1,44):\n",
        "  d_helmet_exp[f'{N}'], d_true_helmet_exp[f'{N}'] = dict_fill(d_helmet[f'{N}'], d_true_helmet[f'{N}']) # выравниваем количество (длины массивов) человек для каждого видео в предсказаниях и эталонах (описание функции выше)\n",
        "  d_unif_exp[f'{N}'], d_true_unif_exp[f'{N}'] = dict_fill(d_unif[f'{N}'], d_true_unif[f'{N}']) # выравниваем количество (длины массивов) человек для каждого видео в предсказаниях и эталонах (описание функции выше)\n",
        "\n",
        "#превращаем значения словарей сначала в список списков а потом в вектор для подачи в склерн\n",
        "d_true_helmet_list = [element for innerList in list(d_true_helmet_exp.values()) for element in innerList] \n",
        "d_helmet_list = [element for innerList in list(d_helmet_exp.values()) for element in innerList] \n",
        "d_true_unif_list = [element for innerList in list(d_true_unif_exp.values()) for element in innerList] \n",
        "d_unif_list = [element for innerList in list(d_unif_exp.values()) for element in innerList] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMBHf3Fks8nI",
        "outputId": "cff7d1f0-0b2a-47e4-a624-95346d029f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R по каскам:  1.0\n",
            "P по каскам:  1.0\n",
            "R по униформе:  0.92\n",
            "P по униформе:  0.98\n"
          ]
        }
      ],
      "source": [
        "\"\"\" \n",
        "1.)Если задача избегать ложных детекций нарушений (у нас нарушения это 0), \n",
        "значит для нас важно не классифицировать 1 как 0 - а это значит, что цель определить все 1 как 1 \n",
        "несмотря сколько 0 будет определно как 1, что в свою очередь означает что целевая метрика - Recall по 1,\n",
        "а не precision как ранее обсуждали\n",
        "2.) С учетом того что у нас нарушения имеют значения 0, а average ='binary' ожидает полчить нарушения \n",
        "в классе 1, мы убираем этот режим и смотрим на метрику класса 1 (это означает что первый класс \n",
        "помещен в числитель метрик P R и метрики вычисляются по нему) - что равносильно бинарному подходу \n",
        "по опредедению R для нарушений которые были бы в классе 1\n",
        "\"\"\"\n",
        "precision, recall,_,_ = precision_recall_fscore_support(d_true_helmet_list, d_helmet_list)\n",
        "precision2, recall2,_,_ = precision_recall_fscore_support(d_true_unif_list, d_unif_list)\n",
        "print('R по каскам: ', round(recall[1],2))\n",
        "print('P по каскам: ', round(precision[1],2))\n",
        "print('R по униформе: ', round(recall2[1],2))\n",
        "print('P по униформе: ', round(precision2[1],2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_true_unif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29S45bphtgXJ",
        "outputId": "d6c49584-c0e4-4a10-ce45-031832206dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': [1, 1, 1],\n",
              " '2': [1, 1, 1],\n",
              " '3': [1, 0, 1],\n",
              " '4': [1, 0, 1, 1],\n",
              " '5': [],\n",
              " '6': [0, 0, 0, 0, 1],\n",
              " '7': [1, 0, 1, 0],\n",
              " '8': [0, 0, 0, 0, 0],\n",
              " '9': [1, 1],\n",
              " '10': [1, 1],\n",
              " '11': [0, 0, 1],\n",
              " '12': [0, 0, 0, 1],\n",
              " '13': [1, 1, 0, 0, 1, 1],\n",
              " '14': [1, 1, 1],\n",
              " '15': [0, 0],\n",
              " '16': [1, 1, 1, 0],\n",
              " '17': [0, 1, 0, 0, 1, 1],\n",
              " '18': [1, 1, 0, 0],\n",
              " '19': [1],\n",
              " '20': [],\n",
              " '21': [0, 0],\n",
              " '22': [0, 1, 0],\n",
              " '23': [0],\n",
              " '24': [1],\n",
              " '25': [0, 0],\n",
              " '26': [0],\n",
              " '27': [0, 1],\n",
              " '28': [0, 1],\n",
              " '29': [0, 0],\n",
              " '30': [0, 1, 1, 1],\n",
              " '31': [1, 1],\n",
              " '32': [],\n",
              " '33': [],\n",
              " '34': [],\n",
              " '35': [],\n",
              " '36': [],\n",
              " '37': [],\n",
              " '38': [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
              " '39': [1],\n",
              " '40': [0],\n",
              " '41': [],\n",
              " '42': [0, 0],\n",
              " '43': []}"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_unif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZgaVeZ_tjbO",
        "outputId": "f06338a6-c3c9-4a8d-eaea-a91ab3b9c8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': [1, 1, 1],\n",
              " '2': [1, 1, 1],\n",
              " '3': [1, 0, 1],\n",
              " '4': [1, 0, 1, 1],\n",
              " '5': [],\n",
              " '6': [0, 0, 0, 0, 0],\n",
              " '7': [0, 1, 0, 0],\n",
              " '8': [0, 0, 0, 0, 0],\n",
              " '9': [1, 1],\n",
              " '10': [1, 1],\n",
              " '11': [0, 0, 1],\n",
              " '12': [0, 0, 0, 1],\n",
              " '13': [1, 1, 0, 0, 1, 1],\n",
              " '14': [1, 1, 1],\n",
              " '15': [0, 0],\n",
              " '16': [1, 1, 0],\n",
              " '17': [0, 1, 0, 1, 1],\n",
              " '18': [1, 1, 0, 0],\n",
              " '19': [1],\n",
              " '20': [],\n",
              " '21': [0, 0],\n",
              " '22': [0, 1, 0],\n",
              " '23': [0],\n",
              " '24': [1],\n",
              " '25': [0, 0],\n",
              " '26': [0],\n",
              " '27': [0, 1],\n",
              " '28': [0, 1],\n",
              " '29': [0, 0],\n",
              " '30': [0, 1, 1, 1],\n",
              " '31': [1, 1],\n",
              " '32': [],\n",
              " '33': [],\n",
              " '34': [],\n",
              " '35': [],\n",
              " '36': [],\n",
              " '37': [],\n",
              " '38': [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
              " '39': [1],\n",
              " '40': [0],\n",
              " '41': [],\n",
              " '42': [0, 0],\n",
              " '43': []}"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdraysvOn0Yr"
      },
      "outputs": [],
      "source": [
        "# отсутсвие нарушения 0 - целевой класс, мы не должны ошибаться на примерах с отсутсвующим нарушением\n",
        "# фиксация нарушения 1\n",
        "\n",
        "d_pred = [0,0,0,0,1,1,1,1,1,1] # одна ложная фиксация нарушения вместо фиксации отсутсвия\n",
        "d_true = [0,0,0,0,0,1,1,1,1,1] \n",
        "cls_1 = classification_report(d_true, d_pred)\n",
        "print('Одна ложная фиксация нарушения вместо фиксации его отстсвия (см. метрики класса 0)')\n",
        "print('recall снизился, precision = 1')\n",
        "print(cls_1)\n",
        "\n",
        "d_pred = [0,1,1,1,1,1,1,1,1,1] \n",
        "d_true = [0,0,0,0,0,1,1,1,1,1] # четыре ложны фиксации нарушения вместо 4 фиксаций отстсвия\n",
        "cls_2 = classification_report(d_true, d_pred)\n",
        "print('четыре ложны фиксации нарушения вместо 4 фиксаций отстсвия (см. метрики класса 0)')\n",
        "print('Все еще precision = 1, снижается precision нецелевого 1го класса')\n",
        "print(cls_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySGuKwRrvaan",
        "outputId": "87f1d001-1c5a-4d2f-dabd-226ea2548551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "пропуск 4 нарушений - допустимо в рамках задачи\n",
            "Все еще precision = 0.2, recall = 1!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      1.00      0.33         1\n",
            "           1       1.00      0.56      0.71         9\n",
            "\n",
            "    accuracy                           0.60        10\n",
            "   macro avg       0.60      0.78      0.52        10\n",
            "weighted avg       0.92      0.60      0.68        10\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# отсутсвие нарушения 0 - целевой класс, мы не должны ошибаться на примерах с отсутсвующим нарушением\n",
        "# фиксация нарушения 1\n",
        "\n",
        "d_pred = [0,0,0,0,0,1,1,1,1,1] \n",
        "d_true = [0,1,1,1,1,1,1,1,1,1] # пропуск 4 нарушений - допустимо в рамках задачи\n",
        "cls_2 = classification_report(d_true, d_pred)\n",
        "print('пропуск 4 нарушений - допустимо в рамках задачи')\n",
        "print('Все еще precision = 0.2, recall = 1!')\n",
        "print(cls_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB7Fb1uU3Xr5",
        "outputId": "08efde8d-54e9-46c1-a3a1-f5aed1e6d9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[          1         0.2]\n",
            "[    0.55556           1]\n"
          ]
        }
      ],
      "source": [
        "# отсутсвие нарушения 0 - целевой класс, мы не должны ошибаться на примерах с отсутсвующим нарушением\n",
        "# фиксация нарушения 1\n",
        "\n",
        "d_pred = [1,1,1,1,1,0,0,0,0,0] \n",
        "d_true = [1,0,0,0,0,0,0,0,0,0] # пропуск 4 нарушений - допустимо в рамках задачи\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision, recall,_,_ = precision_recall_fscore_support(d_true, d_pred)\n",
        "print(precision)\n",
        "print(recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssRyLCFDzFW8",
        "outputId": "f58e5ff6-ef6c-49a2-9156-061ebe7f2b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0]\n",
            "[0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1]\n",
            "[0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(d_true_helmet['7'])\n",
        "print(d_true_helmet['11'])\n",
        "print(d_true_helmet['13'])\n",
        "print(d_true_helmet['14'])\n",
        "print(d_true_helmet['17'])\n",
        "print(d_true_helmet['30'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_ygNqX9tVCL",
        "outputId": "f55d7127-8d0f-4979-d979-48b1d1440d39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(d_true_helmet_exp['7'])\n",
        "print(d_true_helmet_exp['11'])\n",
        "print(d_true_helmet_exp['13'])\n",
        "print(d_true_helmet_exp['14'])\n",
        "print(d_true_helmet_exp['17'])\n",
        "print(d_true_helmet_exp['30'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACOSqQvHtXkz",
        "outputId": "7105a331-67e7-4c6c-b28b-f322eff8bc2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0]\n",
            "[1, 1, 1, 1, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "[1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "d_helmet_exp\n",
        "print(d_helmet_exp['7'])\n",
        "print(d_helmet_exp['11'])\n",
        "print(d_helmet_exp['13'])\n",
        "print(d_helmet_exp['14'])\n",
        "print(d_helmet_exp['17'])\n",
        "print(d_helmet_exp['30'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6ukkflcRQy4"
      },
      "source": [
        "# Гитхаб и ООП "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AZEMcoBT7-M"
      },
      "source": [
        "## mikel-brostrom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32GKyL0zKm-F",
        "outputId": "a0bbac24-46c0-43d9-a6de-00adda567976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyHgalBuHfZE",
        "outputId": "efb2d8c5-ad59-4dba-e2e6-0c3f494acd65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov8_tracking'...\n",
            "remote: Enumerating objects: 4640, done.\u001b[K\n",
            "remote: Total 4640 (delta 0), reused 0 (delta 0), pack-reused 4640\u001b[K\n",
            "Receiving objects: 100% (4640/4640), 109.43 MiB | 40.57 MiB/s, done.\n",
            "Resolving deltas: 100% (2384/2384), done.\n",
            "Submodule 'yolov8' (https://github.com/ultralytics/ultralytics) registered for path 'yolov8'\n",
            "Cloning into '/content/OC_SORT/yolov8_tracking/yolov8'...\n",
            "remote: Enumerating objects: 6287, done.        \n",
            "remote: Counting objects: 100% (206/206), done.        \n",
            "remote: Compressing objects: 100% (133/133), done.        \n",
            "remote: Total 6287 (delta 108), reused 129 (delta 73), pack-reused 6081        \n",
            "Receiving objects: 100% (6287/6287), 5.06 MiB | 19.99 MiB/s, done.\n",
            "Resolving deltas: 100% (4226/4226), done.\n",
            "Submodule path 'yolov8': checked out '15b3b0365ab2f12993a58985f3cb7f2137409a0c'\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '/content/yolov8_tracking/requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!git clone --recurse-submodules https://github.com/mikel-brostrom/yolov8_tracking.git  # clone recursively\n",
        "!cd yolov8_tracking\n",
        "!pip install -r /content/yolov8_tracking/requirements.txt  # install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XhsRmdSFLLO"
      },
      "outputs": [],
      "source": [
        "# Импортируем библиотеки\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y43wzB7ALcTD",
        "outputId": "83d22408-6d47-4d4c-bf29-983ff9f94226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/yolov8_tracking/weights’: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Создаем папку weights в папке репозитория (требуется при запуске трекера)\n",
        "!mkdir /content/yolov8_tracking/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhH0rAjXMJBR",
        "outputId": "4e6b6351-04a6-4b0f-93ae-3b53ec47efb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/yolov8_tracking/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Проверяем наличие папки weights в папке репозитория\n",
        "!ls /content/yolov8_tracking/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M36DV-hfJk1L",
        "outputId": "6ca98891-1850-40a4-bd78-fac02b41e291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python: can't open file '/content/yolov8_tracking/track.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Запускаем трекер\n",
        "!python /content/yolov8_tracking/track.py --yolo-weights /content/drive/MyDrive/AI/Inter_Yolo/best.pt/best14.pt --tracking-method bytetrack --tracking-config /content/bytetrack.yaml --source /content/drive/MyDrive/dataset-v1.1/test/14.mp4 --save-txt --save-conf --save-trajectories --save-vid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRvksHlzuoXJ",
        "outputId": "20e12cfa-39a3-470e-c309-fc67204d5330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ImageNet-Datasets-Downloader'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 127 (delta 4), reused 6 (delta 2), pack-reused 113\u001b[K\n",
            "Receiving objects: 100% (127/127), 1.58 MiB | 8.86 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --recurse-submodules https://github.com/mf1024/ImageNet-Datasets-Downloader.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq3DLhBBoQI2"
      },
      "source": [
        "## ООП"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBtMjt9nul9L"
      },
      "source": [
        "##install and import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFVCNi3xWzJT",
        "outputId": "ec133af3-3258-4bef-b87d-5f2245e1641d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.9/dist-packages (8.0.68)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from ultralytics) (5.9.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.0.0+cu118)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.4.4)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (8.4.0)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.15.1+cu118)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.19.1)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.22.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.10.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->ultralytics) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M3zu31df-G_",
        "outputId": "10f5b3ed-798d-4317-b355-5c0648135d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html!\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision -f https://download.pytorch.org/whl/torch_stable.html!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx4v7M0DV-J5",
        "outputId": "694d7fea-97b2-4209-8b1e-90f4b083fc32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv8 requirement \"lap>=0.4\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lap>=0.4\n",
            "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 20.9 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Building wheels for collected packages: lap\n",
            "  Building wheel for lap (setup.py): started\n",
            "  Building wheel for lap (setup.py): finished with status 'done'\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp39-cp39-linux_x86_64.whl size=1655021 sha256=90361ce8d202466847b7c045f37e175a5f7b18cf81aaabd84e72075f40892c45\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/8b/30/e7dd4f9dc44fb438381df571c9a6bddc35aafd1bf39c4f8911\n",
            "Successfully built lap\n",
            "Installing collected packages: lap\n",
            "Successfully installed lap-0.4.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ['lap>=0.4']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import operator\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.tracker import BOTSORT\n",
        "from ultralytics.tracker import BOTSORT\n",
        "from ultralytics.tracker.track import on_predict_start\n",
        "# from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from ultralytics.yolo.utils.checks import check_requirements\n",
        "# from ultralytics.yolo.utils.plotting import save_one_box, colors\n",
        "from ultralytics.yolo.v8.detect import DetectionPredictor\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv6jI268WygK"
      },
      "outputs": [],
      "source": [
        "check_requirements('lap')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De9BjBgi34kM",
        "outputId": "9c1e5084-f109-4edf-c784-b902e04a4d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfP49MjGnWmU"
      },
      "source": [
        "##Detect and post-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unFzU0dqyTGO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "908vdRz0-jTz"
      },
      "outputs": [],
      "source": [
        "class MyDetectionPredictor2(DetectionPredictor):\n",
        "    track_id_barrier = defaultdict(list)\n",
        "    barrier_y = 370\n",
        "    track_dict = {}\n",
        "    barrier_zone = 5\n",
        "\n",
        "    @staticmethod\n",
        "    def get_coord_y(coord_y, last_y):\n",
        "        return coord_y - last_y > 0\n",
        "\n",
        "    @staticmethod\n",
        "    def get_y_center(arr):\n",
        "        center_y = ((abs((arr[:, 3] - arr[:, 2])) / 2) + arr[:, 2])\n",
        "        return center_y\n",
        "\n",
        "    def get_control_walk(self, last_y, id_human, y_coord):\n",
        "        operator_walk, text = (operator.gt, 'Вышел') if last_y > 0 else (operator.lt, 'Вошел')\n",
        "\n",
        "        if operator_walk(self.barrier_y, y_coord):\n",
        "            print('+' * 100)\n",
        "            print('id_human', id_human, text)\n",
        "            print('+' * 100)\n",
        "            self.track_dict.pop(id_human, None)\n",
        "\n",
        "    def write_results(self, idx, results, batch):\n",
        "        log_string = ''\n",
        "        tracks = []\n",
        "        det_track = results[idx].boxes.cpu().numpy()\n",
        "        det_track_not_human = det_track[det_track.cls != 0]\n",
        "        det_track_human = det_track[det_track.cls == 0]\n",
        "        if det_track_human:\n",
        "            self.results[idx].update(boxes=torch.as_tensor(det_track_human.boxes))\n",
        "            self.res_coord = [coord for coord in det_track_human.boxes]\n",
        "\n",
        "        im0s = self.batch[2]\n",
        "        im0s = im0s if isinstance(im0s, list) else [im0s]\n",
        "\n",
        "        if hasattr(self, 'trackers'):\n",
        "            tracks = self.trackers[0].update(det_track_human, im0s[0])\n",
        "\n",
        "        if len(tracks) == 0:\n",
        "            return super().write_results(idx, results, batch)\n",
        "        ########################################################################\n",
        "        id_array = tracks[:, 4]\n",
        "\n",
        "        y = self.get_y_center(tracks)\n",
        "\n",
        "        tracks_array = tracks[np.in1d(tracks[:, 4], list(self.track_dict.keys()))]\n",
        "        for y_coord, id_human in zip(self.get_y_center(tracks_array), tracks_array[:, 4]):\n",
        "            last_y = self.track_dict.get(id_human)\n",
        "            self.get_control_walk(last_y, id_human, y_coord)\n",
        "\n",
        "        for c_y, id_human in zip(y, id_array):\n",
        "            dst = c_y - self.barrier_y\n",
        "            if abs(dst) < self.barrier_zone:#От барьера 5 в обе стороны\n",
        "                self.track_dict.update({id_human: dst})\n",
        "        ########################################################################\n",
        "\n",
        "        self.results[idx].update(boxes=torch.as_tensor(tracks[:, :-1]))\n",
        "        log_string += super().write_results(idx, self.results, batch)\n",
        "\n",
        "        return log_string\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qce7qs_3WfQa"
      },
      "outputs": [],
      "source": [
        "def init_model(track=True, model=\"yolov8s.pt\"):\n",
        "    my_model = YOLO(model=model)\n",
        "    if track:\n",
        "        my_model.predictor = MyDetectionPredictor2()\n",
        "    return my_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emz9jTxfEmzv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "fgr620dhWjIs",
        "outputId": "83652508-93a3-4fed-baf6-4d2195fca599"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to yolov8s.pt...\n",
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 107MB/s]\n",
            "\n",
            "Ultralytics YOLOv8.0.68 🚀 Python-3.9.16 torch-2.0.0+cu118 CPU\n",
            "YOLOv8s summary (fused): 168 layers, 11156544 parameters, 0 gradients, 28.6 GFLOPs\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-455048b9d8ba>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_thickness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#По 4 посетителю середина (Y) прыгнула поэтому и зашел и вышел\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-455048b9d8ba>\u001b[0m in \u001b[0;36mpredict_model\u001b[0;34m(source, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'track'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_predict_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# only update args if predictor is already setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# predict, segment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         self.dataset = load_inference_source(source=source,\n\u001b[0m\u001b[1;32m    141\u001b[0m                                              \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                                              \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, transforms, imgsz, vid_stride, stride, auto)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadPilAndNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         dataset = LoadImages(source,\n\u001b[0m\u001b[1;32m    187\u001b[0m                              \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                              \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/data/dataloaders/stream_loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, imgsz, stride, auto, transforms, vid_stride)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{p} does not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mIMG_FORMATS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: /content/OC_SORT/1.mp4 does not exist"
          ]
        }
      ],
      "source": [
        "def predict_model(source=None, **kwargs):\n",
        "    event = 'on_predict_start'\n",
        "    my_model = init_model()\n",
        "    # kwargs = {}\n",
        "    # conf = 0.1\n",
        "    # kwargs['conf'] = conf\n",
        "    kwargs['mode'] = 'track'\n",
        "    my_model.add_callback(event, on_predict_start)\n",
        "    result = my_model.predict(source=source, **kwargs)\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "result = predict_model(source='1.mp4', save=True, classes=0, line_thickness=1)\n",
        "#По 4 посетителю середина (Y) прыгнула поэтому и зашел и вышел "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1xtU-eAqH5J"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs3c6SjBjZ7a"
      },
      "outputs": [],
      "source": [
        "\n",
        "for key, value in data[1].items():\n",
        "  print(f'Нарушитель с id-{key} ')\n",
        "  for v in value:\n",
        "      \n",
        "      print(f'номер нарушения-{v[0]}, момент нарушения -{v[1].split()[:-1]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Ac_LC89QrO"
      },
      "source": [
        "### Track\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_kNdPJf8m9a"
      },
      "outputs": [],
      "source": [
        "def init_track_model():\n",
        "    my_model = YOLO()\n",
        "    my_model.track(source='/content/gdrive/MyDrive/My_dataset/dataset-v1.1/test/1.mp4', save=True, save_txt=True)\n",
        "    return my_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1s-GeLph9LwZ"
      },
      "outputs": [],
      "source": [
        "init_track_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91tGcrxxH92w"
      },
      "source": [
        "## Dimar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMunfSCYCpFA"
      },
      "outputs": [],
      "source": [
        "# Подключаем диск: на диске видео и потом туда сохраняем labels и видео с результатами.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcz6EMMDcGYU",
        "outputId": "1cfee436-4b18-4c35-e598-e59c978aa474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 2240, done.\u001b[K\n",
            "remote: Counting objects: 100% (568/568), done.\u001b[K\n",
            "remote: Compressing objects: 100% (191/191), done.\u001b[K\n",
            "remote: Total 2240 (delta 379), reused 565 (delta 376), pack-reused 1672\u001b[K\n",
            "Receiving objects: 100% (2240/2240), 143.21 MiB | 23.79 MiB/s, done.\n",
            "Resolving deltas: 100% (1352/1352), done.\n",
            "Updating files: 100% (248/248), done.\n",
            "/content/yolov7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (1.10.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (0.15.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (4.65.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n",
            "Collecting filterpy>=1.4.5\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image>=0.17.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (0.19.3)\n",
            "Collecting lap>=0.4.0\n",
            "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 19)) (1.2.2)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.72-py3-none-any.whl (511 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.0/511.0 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (2.12.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 22)) (4.6.6)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 23)) (0.56.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (2.12.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 30)) (1.4.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 31)) (0.12.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 43)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 44)) (5.9.4)\n",
            "Collecting thop~=0.1.1.post2209072238\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 51)) (1.10)\n",
            "Collecting deep_sort_realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting norfair-tracker\n",
            "  Downloading norfair_tracker-0.0.4.tar.gz (4.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting DNN\n",
            "  Downloading dnn-0.7.4-py3-none-any.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 55)) (3.0.10)\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 KB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (5.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.12)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.5.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (16.0.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.17.2->-r requirements.txt (line 17)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.17.2->-r requirements.txt (line 17)) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.17.2->-r requirements.txt (line 17)) (2023.3.21)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 19)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 19)) (1.1.1)\n",
            "Collecting sentry-sdk\n",
            "  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (16.0.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (1.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (2.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (67.6.1)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (0.4.7)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (1.53.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (3.8.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (0.32.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (1.16.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (0.4.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 21)) (2.12.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown->-r requirements.txt (line 22)) (4.11.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->-r requirements.txt (line 23)) (0.39.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 26)) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 26)) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 26)) (0.40.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 26)) (3.4.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 26)) (2.17.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 26)) (0.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 26)) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 30)) (2022.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 43)) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 43)) (2.14.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 43)) (4.8.0)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 43)) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 43)) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 43)) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 43)) (0.7.5)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 43)) (0.1.6)\n",
            "Collecting norfair==2.1.1\n",
            "  Downloading norfair-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich<13.0.0,>=9.10.0\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 KB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tfserver\n",
            "  Downloading tfserver-0.4.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from DNN->-r requirements.txt (line 54)) (0.18.3)\n",
            "Collecting exif\n",
            "  Downloading exif-1.6.0-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.9/dist-packages (from DNN->-r requirements.txt (line 54)) (0.2.7)\n",
            "Collecting webrtcvad\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fdet\n",
            "  Downloading fdet-0.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting rs4\n",
            "  Downloading rs4-0.3.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.4/628.4 KB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl->-r requirements.txt (line 55)) (1.1.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.3-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 KB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna->-r requirements.txt (line 56)) (1.4.47)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 26)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 26)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 26)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 26)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.15.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow->-r requirements.txt (line 21)) (0.0.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 43)) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 26)) (6.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 43)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 43)) (0.2.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna->-r requirements.txt (line 56)) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 26)) (2.1.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 22)) (2.4)\n",
            "Collecting plum-py<2.0.0,>=0.5.0\n",
            "  Downloading plum_py-0.8.6-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from fdet->DNN->-r requirements.txt (line 54)) (8.1.3)\n",
            "Collecting ttictoc\n",
            "  Downloading ttictoc-0.5.6-py3-none-any.whl (5.7 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting colour\n",
            "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from hyperopt->DNN->-r requirements.txt (line 54)) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.9/dist-packages (from hyperopt->DNN->-r requirements.txt (line 54)) (0.10.9.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.7.1)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Collecting atila\n",
            "  Downloading atila-0.26.11-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 26)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 26)) (3.2.2)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting skitai>=0.56.9\n",
            "  Downloading skitai-0.56.10-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2>=4.0.0\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlphile>=0.9\n",
            "  Downloading sqlphile-0.9.7-py3-none-any.whl (27 kB)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: filterpy, lap, norfair-tracker, webrtcvad\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110473 sha256=f8e8bf6e8069d2b84de0852fd2bfcd205997492756f6fe8b490a144149d54199\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/e6/de/a09ea01e923aaf88b9f8c7c44329e857b2c1a31901167e55e6\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp39-cp39-linux_x86_64.whl size=1655051 sha256=4d77043a631461f7d1d46aaaf978982d03b77a787c347dac1d4dc9b9b6888fef\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/8b/30/e7dd4f9dc44fb438381df571c9a6bddc35aafd1bf39c4f8911\n",
            "  Building wheel for norfair-tracker (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for norfair-tracker: filename=norfair_tracker-0.0.4-py3-none-any.whl size=3880 sha256=c354afe7fa0896ef19013b786ac578ca48b01149013c7d3c23d44632b1726781\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/3d/a1/4a628361f332e632a8d6bfa8c5fe3d168814cf28b9d2a06da8\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp39-cp39-linux_x86_64.whl size=80905 sha256=068f5ee96d7ed4dc722b15b1ea86af9ed784600900849bbc066acb482f14e7f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/fe/28/e8f0d5847ae2642b49fa974db1cea44d59ab59d0251c12f17b\n",
            "Successfully built filterpy lap norfair-tracker webrtcvad\n",
            "Installing collected packages: webrtcvad, ttictoc, lap, commonmark, colour, setproctitle, sentry-sdk, rich, plum-py, Mako, jedi, hyperframe, hpack, dill, colorlog, colorama, cmaes, rs4, h2, fdet, exif, deep_sort_realtime, alembic, sqlphile, optuna, filterpy, skitai, norfair, norfair-tracker, atila, tfserver, DNN, thop, ultralytics\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.3.3\n",
            "    Uninstalling rich-13.3.3:\n",
            "      Successfully uninstalled rich-13.3.3\n",
            "Successfully installed DNN-0.7.4 Mako-1.2.4 alembic-1.10.3 atila-0.26.11 cmaes-0.9.1 colorama-0.4.6 colorlog-6.7.0 colour-0.1.5 commonmark-0.9.1 deep_sort_realtime-1.3.2 dill-0.3.6 exif-1.6.0 fdet-0.2.1 filterpy-1.4.5 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 jedi-0.18.2 lap-0.4.0 norfair-2.1.1 norfair-tracker-0.0.4 optuna-3.1.1 plum-py-0.8.6 rich-12.6.0 rs4-0.3.23 sentry-sdk-1.19.1 setproctitle-1.3.2 skitai-0.56.10 sqlphile-0.9.7 tfserver-0.4.9 thop-0.1.1.post2209072238 ttictoc-0.5.6 ultralytics-8.0.72 webrtcvad-2.0.10\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dimarsoft/yolov7.git\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt  # install dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi-pBng9Mk-i"
      },
      "source": [
        "**Трекинг по уже полученным тхт файлам**\n",
        "\n",
        "Так же можно реализовать свой фукцию изменения bbox для трекера\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCHHIdu4rBkX"
      },
      "outputs": [],
      "source": [
        "# ничего не меняет, просто print\n",
        "def not_change_bbox(bbox, file_id):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        file_id(str): имя файла \n",
        "        bbox (tensor): первые 4ре столбца x1 y1 x2 y2 \n",
        "        в абсолютных значениях картинки.\n",
        "        Пока это ббоксы всех классов, \n",
        "        сам класс находится в последнем столбце (-1, или индекс 5)\n",
        "    \"\"\"\n",
        "    print(f\"file = {file_id}\")\n",
        "    return bbox\n",
        "\n",
        "# пример реалиции бокса по центру 20/20\n",
        "def change_bbox_to_center(bbox, file_id):\n",
        "    x1 = (bbox[:, [0]] + bbox[:, [2]]) / 2\n",
        "    y1 = (bbox[:, [1]] + bbox[:, [3]]) / 2\n",
        "\n",
        "    w = 10  \n",
        "    h = 10  \n",
        "\n",
        "    bbox[:, [0]] = x1 - w\n",
        "    bbox[:, [2]] = x1 + w\n",
        "\n",
        "    bbox[:, [1]] = y1 - h\n",
        "    bbox[:, [3]] = y1 + h\n",
        "\n",
        "    return bbox    \n",
        "\n",
        "# пример реалиции от Павла (группа №1)\n",
        "def pavel_change_bbox(bbox, file_id):\n",
        "    y2 = bbox[:, [1]] + 150\n",
        "\n",
        "    bbox[:, [3]] = y2\n",
        "\n",
        "    return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJWT7B32Mx8D"
      },
      "outputs": [],
      "source": [
        "from yolo_track_by_txt import run_track_yolo\n",
        "from configs import get_all_trackers_full_path\n",
        "\n",
        "# путь к файлу/папке, если указать путь к папке, то обработает все видео\n",
        "video_source = \"/content/drive/MyDrive/dataset-v1.1/test\" \n",
        "\n",
        "\n",
        "files= None # [\"1\", \"2\"] # None # ['1']\n",
        "files= [\"1\"] # None # ['1']\n",
        "\n",
        "# classes спискок классов. [0] # [0, 1] # список классов, None все. 0 - человек. \n",
        "# это нужно к примеру когда используется предобученная модель, в которой много классов, но нам нужен только один человек\n",
        "# или хотим посмотреть когда трекер только по одному классу работает\n",
        "classes = None\n",
        "# создание видео \n",
        "save_vid=True\n",
        "save_txt=True\n",
        "\n",
        "change_bb = None # change_bbox_to_center\n",
        "\n",
        "# путь к текстовым файла (папка)\n",
        "txt_source_folder = \"/content/drive/MyDrive/AI_2023/2023_03_27_15_05_37_YoloVersion.yolo_v8_detect\"\n",
        "txt_source_folder = \"/content/drive/MyDrive/AI_2023/Detections/2023_03_29_10_35_01_YoloVersion.yolo_v7_detect\"\n",
        "# папка для сохранения информации, пока тхт, потом наше видео, постобработка\n",
        "# в ней создается папка с датой, там будут видео появляться, тхт файлы и в конце результата постобработки и сравнения с эталоном\n",
        "output_folder = \"/content/drive/MyDrive/AI_2023/\"\n",
        "\n",
        "reid_weights = \"osnet_x0_25_msmt17.pt\"\n",
        "test_file = \"/content/yolov7/testinfo/all_track_results.json\"\n",
        "\n",
        "\n",
        "\n",
        "# в репозитории есть именные фукции постобработки: \"timur\", \"popov_alex\", \"dimar\"\n",
        "# если указать строку, то будет выполняться код из репозитория\n",
        "# post_processing/alex.py, post_processing/timur.py\n",
        "# в функции run_track_yolo есть параметр test_func: test_func=имя фукции для постобработки\n",
        "# имя функции для постобработки может быть любое , допустимое в python\n",
        "\n",
        "test_func = None\n",
        "\n",
        "\n",
        "# все доступные трекеры\n",
        "all_trackers = get_all_trackers_full_path()\n",
        "\n",
        "# пример для norfair\n",
        "tracker_name = \"norfair\"\n",
        "tracker_config = all_trackers.get(tracker_name)\n",
        "\n",
        "# или как ранее\n",
        "# tracker_config = \"/content/yolov7/trackers/NorFairTracker/configs/norfair_track.yaml\"\n",
        "\n",
        "# 1. запуск одного трекера\n",
        "run_track_yolo(txt_source_folder, video_source, tracker_name, tracker_config,\n",
        "               output_folder, reid_weights, test_file, test_func=test_func, files=files, \n",
        "               save_vid=save_vid, change_bb=change_bb)\n",
        "\n",
        "# список доступных трекеров\n",
        "\n",
        "for key in all_trackers.keys():\n",
        "  print(f\"{key} : {all_trackers[key]}\")\n",
        "\n",
        "\n",
        "# 2. запуск всех трекеров , но в одной сессии: папка одна бедт общпя для всех трекеров\n",
        "\n",
        "# указываем словарь, run_track_yolo по нему отработает\n",
        "tracker_name = all_trackers\n",
        "\n",
        "run_track_yolo(txt_source_folder, video_source, tracker_name, tracker_config,\n",
        "               output_folder, reid_weights, test_file, test_func=test_func, files=files, \n",
        "               save_vid=save_vid, change_bb=change_bb)\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "We1jVACPJqy7",
        "xT6enxDcJqzG",
        "6AZEMcoBT7-M",
        "hBtMjt9nul9L",
        "sfP49MjGnWmU"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
